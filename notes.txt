------ C'est quoi un neuronne ? Chapitre 1

Couche d'entrée => sous-couches (choix arbitraire) => couche de sortie
Chaque liaison a un poids, qui peut etre négatif ou positif
Matrice(somme des poids) x Matrice(valeur neuronne) + Matrice(biais)
Signoid de chaque élément de la matrice
Chaque neuronne peut etre activé ou pas

------ Descente de gradients - Chepitre 2

Fonction de coût (calculée en fonction des poids et biais
Gradient max = Valeur de la pente où elle est la plus raide
Gradient min = Inverse du max
Descente de gradient = Converger vers un minimum local
Structure de données ordonnée => plus facile a traiter

------ Rétropopagation - Chapitre 3

Sert a ajuster les poids et les biais pour réduire les coûts le plus rapidement possible
Calculer le pourcentage de réduction ou augmentation

------ Calculs - Chapitre 4

Notion de Dérivation en chaine

------ Les models de language en bref

Transformers => Assimilent le texte en paralèle au lieu de le lire linéairement
Chaque mot d'un prompt est associé à une suite de nombre (encodé)
Attention => Affiner chaque nombre auquel est associé un mot

------ Mais c'est quoi un GPT ? Chapitre 5

Chaque mot ou petit extrait de texte est un token
Transformer => type particulier de réseau de neuronne qui sert à entrainer le model
Embedding => représentation de vecteurs de données dans un espace dimentionnel
Gpt2 et Gpt3 la différence est un plus large model de données d'entrainement

------ MNIST

Neuronne de convolution => 9 entrées et 1 biais donc 10 poids

